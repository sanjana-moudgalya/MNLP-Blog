<!DOCTYPE html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-beta.51" />
    <meta name="theme" content="VuePress Theme Hope" />
    <meta property="og:url" content="https://lileicc.github.io/blog/dl4mt/2021/lass/"><meta property="og:site_name" content="Evaluation of Machine Translations with Large Language Models"><meta property="og:title" content="Exploiting Capacity for Multilingual Neural Machine Translation"><meta property="og:type" content="article"><meta property="og:image" content="https://lileicc.github.io/blog/"><meta property="og:updated_time" content="2022-09-13T03:45:15.000Z"><meta property="og:locale" content="en-US"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image:alt" content="Exploiting Capacity for Multilingual Neural Machine Translation"><meta property="article:author" content="Wenda Xu"><meta property="article:tag" content="Multilingual MT"><meta property="article:tag" content="Model Capacity"><meta property="article:tag" content="Language-specific Sub-network"><meta property="article:published_time" content="2021-11-19T00:00:00.000Z"><meta property="article:modified_time" content="2022-09-13T03:45:15.000Z"><title>Exploiting Capacity for Multilingual Neural Machine Translation | Evaluation of Machine Translations with Large Language Models</title><meta name="description" content="A Blog for Machine Learning, Natural Language Processing, and Data Mining">
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d2025;
      }

      html,
      body {
        background-color: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.querySelector("html").setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="stylesheet" href="/blog/assets/style.758fbe27.css">
    <link rel="modulepreload" href="/blog/assets/app.a9a8508d.js"><link rel="modulepreload" href="/blog/assets/index.html.ad355bca.js"><link rel="modulepreload" href="/blog/assets/_plugin-vue_export-helper.cdc0426e.js"><link rel="modulepreload" href="/blog/assets/index.html.27face02.js"><link rel="prefetch" href="/blog/assets/index.html.82330bce.js"><link rel="prefetch" href="/blog/assets/index.html.b4820c43.js"><link rel="prefetch" href="/blog/assets/index.html.af0611fe.js"><link rel="prefetch" href="/blog/assets/index.html.31ac759e.js"><link rel="prefetch" href="/blog/assets/index.html.de340f50.js"><link rel="prefetch" href="/blog/assets/index.html.7acf364e.js"><link rel="prefetch" href="/blog/assets/index.html.31a5ebff.js"><link rel="prefetch" href="/blog/assets/index.html.35aef74f.js"><link rel="prefetch" href="/blog/assets/index.html.d6ce17b6.js"><link rel="prefetch" href="/blog/assets/index.html.0225a2ca.js"><link rel="prefetch" href="/blog/assets/index.html.b523c8de.js"><link rel="prefetch" href="/blog/assets/index.html.92d2aaf6.js"><link rel="prefetch" href="/blog/assets/index.html.939c0221.js"><link rel="prefetch" href="/blog/assets/index.html.7188a596.js"><link rel="prefetch" href="/blog/assets/index.html.c7e82583.js"><link rel="prefetch" href="/blog/assets/index.html.5cd24471.js"><link rel="prefetch" href="/blog/assets/index.html.2176ea05.js"><link rel="prefetch" href="/blog/assets/index.html.e359ca90.js"><link rel="prefetch" href="/blog/assets/index.html.031a8191.js"><link rel="prefetch" href="/blog/assets/index.html.9f7d8bf9.js"><link rel="prefetch" href="/blog/assets/index.html.2e911ffc.js"><link rel="prefetch" href="/blog/assets/index.html.3f2aecab.js"><link rel="prefetch" href="/blog/assets/index.html.49604b79.js"><link rel="prefetch" href="/blog/assets/404.html.59787e8e.js"><link rel="prefetch" href="/blog/assets/index.html.cc14d178.js"><link rel="prefetch" href="/blog/assets/index.html.a109cb94.js"><link rel="prefetch" href="/blog/assets/index.html.94e05402.js"><link rel="prefetch" href="/blog/assets/index.html.6b571690.js"><link rel="prefetch" href="/blog/assets/index.html.856473f2.js"><link rel="prefetch" href="/blog/assets/index.html.c0c76ade.js"><link rel="prefetch" href="/blog/assets/index.html.882e3639.js"><link rel="prefetch" href="/blog/assets/index.html.58856c4f.js"><link rel="prefetch" href="/blog/assets/index.html.5c96f550.js"><link rel="prefetch" href="/blog/assets/index.html.64a74ec6.js"><link rel="prefetch" href="/blog/assets/index.html.b5e85f83.js"><link rel="prefetch" href="/blog/assets/index.html.90a4f45d.js"><link rel="prefetch" href="/blog/assets/index.html.e9e914f8.js"><link rel="prefetch" href="/blog/assets/index.html.4191bc30.js"><link rel="prefetch" href="/blog/assets/index.html.7cf210f0.js"><link rel="prefetch" href="/blog/assets/index.html.bb46e4f1.js"><link rel="prefetch" href="/blog/assets/index.html.216b3605.js"><link rel="prefetch" href="/blog/assets/index.html.bb90cee8.js"><link rel="prefetch" href="/blog/assets/index.html.3b7e1ca2.js"><link rel="prefetch" href="/blog/assets/index.html.25c9f437.js"><link rel="prefetch" href="/blog/assets/index.html.182526c8.js"><link rel="prefetch" href="/blog/assets/index.html.fef5b721.js"><link rel="prefetch" href="/blog/assets/index.html.6ab84ff4.js"><link rel="prefetch" href="/blog/assets/index.html.2c18330b.js"><link rel="prefetch" href="/blog/assets/index.html.4b52df9d.js"><link rel="prefetch" href="/blog/assets/index.html.30b0b857.js"><link rel="prefetch" href="/blog/assets/index.html.3c44a93a.js"><link rel="prefetch" href="/blog/assets/index.html.723455ff.js"><link rel="prefetch" href="/blog/assets/index.html.75038d8b.js"><link rel="prefetch" href="/blog/assets/index.html.fe3db115.js"><link rel="prefetch" href="/blog/assets/index.html.b9844ab9.js"><link rel="prefetch" href="/blog/assets/index.html.ae97cc6c.js"><link rel="prefetch" href="/blog/assets/index.html.881fc913.js"><link rel="prefetch" href="/blog/assets/index.html.381389fa.js"><link rel="prefetch" href="/blog/assets/index.html.7c92db99.js"><link rel="prefetch" href="/blog/assets/index.html.6cd5f658.js"><link rel="prefetch" href="/blog/assets/index.html.0976c953.js"><link rel="prefetch" href="/blog/assets/index.html.fbb965f6.js"><link rel="prefetch" href="/blog/assets/index.html.8773a42f.js"><link rel="prefetch" href="/blog/assets/index.html.fce7b5db.js"><link rel="prefetch" href="/blog/assets/index.html.cdb04366.js"><link rel="prefetch" href="/blog/assets/index.html.7e14f8ec.js"><link rel="prefetch" href="/blog/assets/index.html.da686a07.js"><link rel="prefetch" href="/blog/assets/index.html.7011bcba.js"><link rel="prefetch" href="/blog/assets/index.html.b65a6432.js"><link rel="prefetch" href="/blog/assets/index.html.97acc0c8.js"><link rel="prefetch" href="/blog/assets/index.html.4b00e402.js"><link rel="prefetch" href="/blog/assets/index.html.831e6a8d.js"><link rel="prefetch" href="/blog/assets/index.html.4c7870b8.js"><link rel="prefetch" href="/blog/assets/index.html.2ee6780e.js"><link rel="prefetch" href="/blog/assets/index.html.cdd62766.js"><link rel="prefetch" href="/blog/assets/index.html.2c3d56b5.js"><link rel="prefetch" href="/blog/assets/index.html.8173e4d5.js"><link rel="prefetch" href="/blog/assets/index.html.7a9dd95b.js"><link rel="prefetch" href="/blog/assets/index.html.f168b040.js"><link rel="prefetch" href="/blog/assets/index.html.3f932e1a.js"><link rel="prefetch" href="/blog/assets/index.html.4fa82859.js"><link rel="prefetch" href="/blog/assets/index.html.f672afa1.js"><link rel="prefetch" href="/blog/assets/index.html.f922631c.js"><link rel="prefetch" href="/blog/assets/index.html.0bfd85e7.js"><link rel="prefetch" href="/blog/assets/index.html.663cafd9.js"><link rel="prefetch" href="/blog/assets/index.html.40430dee.js"><link rel="prefetch" href="/blog/assets/index.html.1b6132a1.js"><link rel="prefetch" href="/blog/assets/index.html.130379bf.js"><link rel="prefetch" href="/blog/assets/index.html.1212ada9.js"><link rel="prefetch" href="/blog/assets/index.html.ee57aca7.js"><link rel="prefetch" href="/blog/assets/index.html.db5adc3a.js"><link rel="prefetch" href="/blog/assets/index.html.20f89990.js"><link rel="prefetch" href="/blog/assets/index.html.88940f61.js"><link rel="prefetch" href="/blog/assets/index.html.a5841e78.js"><link rel="prefetch" href="/blog/assets/index.html.a6eee488.js"><link rel="prefetch" href="/blog/assets/index.html.fb638729.js"><link rel="prefetch" href="/blog/assets/index.html.527a257c.js"><link rel="prefetch" href="/blog/assets/index.html.728ca1db.js"><link rel="prefetch" href="/blog/assets/index.html.5bfa402c.js"><link rel="prefetch" href="/blog/assets/index.html.18a1f776.js"><link rel="prefetch" href="/blog/assets/404.html.81a48f4e.js"><link rel="prefetch" href="/blog/assets/index.html.67453dea.js"><link rel="prefetch" href="/blog/assets/index.html.d7900ddf.js"><link rel="prefetch" href="/blog/assets/index.html.f38a5faf.js"><link rel="prefetch" href="/blog/assets/index.html.fd6a7132.js"><link rel="prefetch" href="/blog/assets/index.html.3d2f7406.js"><link rel="prefetch" href="/blog/assets/index.html.665a1ad9.js"><link rel="prefetch" href="/blog/assets/index.html.e7194be9.js"><link rel="prefetch" href="/blog/assets/index.html.25aca99d.js"><link rel="prefetch" href="/blog/assets/index.html.570be432.js"><link rel="prefetch" href="/blog/assets/index.html.fb061750.js"><link rel="prefetch" href="/blog/assets/index.html.0e7bc6e4.js"><link rel="prefetch" href="/blog/assets/index.html.171e187e.js"><link rel="prefetch" href="/blog/assets/index.html.9cc19118.js"><link rel="prefetch" href="/blog/assets/index.html.c9f7f9b8.js"><link rel="prefetch" href="/blog/assets/index.html.d3400911.js"><link rel="prefetch" href="/blog/assets/index.html.681f2e1d.js"><link rel="prefetch" href="/blog/assets/index.html.d69603a1.js"><link rel="prefetch" href="/blog/assets/index.html.97c2091f.js"><link rel="prefetch" href="/blog/assets/index.html.20cb8ca0.js"><link rel="prefetch" href="/blog/assets/index.html.1016cb66.js"><link rel="prefetch" href="/blog/assets/index.html.29687ef7.js"><link rel="prefetch" href="/blog/assets/index.html.c3236737.js"><link rel="prefetch" href="/blog/assets/index.html.cd0b9ad9.js"><link rel="prefetch" href="/blog/assets/index.html.6d1f7947.js"><link rel="prefetch" href="/blog/assets/index.html.28938375.js"><link rel="prefetch" href="/blog/assets/index.html.6091257a.js"><link rel="prefetch" href="/blog/assets/index.html.fdae1424.js"><link rel="prefetch" href="/blog/assets/index.html.675a0788.js"><link rel="prefetch" href="/blog/assets/index.html.c9b86987.js"><link rel="prefetch" href="/blog/assets/index.html.d3ade91d.js"><link rel="prefetch" href="/blog/assets/index.html.5a2222ce.js"><link rel="prefetch" href="/blog/assets/index.html.c2b8091a.js"><link rel="prefetch" href="/blog/assets/index.html.a3075094.js"><link rel="prefetch" href="/blog/assets/index.html.a30680ef.js"><link rel="prefetch" href="/blog/assets/index.html.65515bcc.js"><link rel="prefetch" href="/blog/assets/index.html.78355e33.js"><link rel="prefetch" href="/blog/assets/index.html.02e614ea.js"><link rel="prefetch" href="/blog/assets/index.html.7900fb53.js"><link rel="prefetch" href="/blog/assets/index.html.664d4d73.js"><link rel="prefetch" href="/blog/assets/index.html.d038acfd.js"><link rel="prefetch" href="/blog/assets/index.html.7d589777.js"><link rel="prefetch" href="/blog/assets/index.html.57797082.js"><link rel="prefetch" href="/blog/assets/index.html.fb499b31.js"><link rel="prefetch" href="/blog/assets/index.html.fb11a387.js"><link rel="prefetch" href="/blog/assets/index.html.accd7e08.js"><link rel="prefetch" href="/blog/assets/index.html.544a40fe.js"><link rel="prefetch" href="/blog/assets/index.html.54cc89fe.js"><link rel="prefetch" href="/blog/assets/index.html.6c9f3865.js"><link rel="prefetch" href="/blog/assets/index.html.20ec5000.js"><link rel="prefetch" href="/blog/assets/index.html.a51dbb11.js"><link rel="prefetch" href="/blog/assets/index.html.fefab277.js"><link rel="prefetch" href="/blog/assets/index.html.5c234697.js"><link rel="prefetch" href="/blog/assets/index.html.ac486b79.js"><link rel="prefetch" href="/blog/assets/giscus.15440425.js"><link rel="prefetch" href="/blog/assets/highlight.esm.d982e650.js"><link rel="prefetch" href="/blog/assets/markdown.esm.832a189d.js"><link rel="prefetch" href="/blog/assets/math.esm.a3f84b6f.js"><link rel="prefetch" href="/blog/assets/notes.esm.3c361cb7.js"><link rel="prefetch" href="/blog/assets/reveal.esm.b96f05d8.js"><link rel="prefetch" href="/blog/assets/search.esm.80da4a02.js"><link rel="prefetch" href="/blog/assets/zoom.esm.8514a202.js"><link rel="prefetch" href="/blog/assets/photoswipe.esm.382b1873.js">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="skip-link sr-only">Skip to content</a><!--]--><div class="theme-container no-sidebar has-toc"><!--[--><!--[--><header class="navbar"><div class="navbar-left"><button class="toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><a href="/blog/" class="brand"><img class="logo" src="/blog/logo.svg" alt="Evaluation of Machine Translations with Large Language Models"><!----><span class="site-name hide-in-pad">Evaluation of Machine Translations with Large Language Models</span></a><!----></div><div class="navbar-center"><!----><nav class="nav-links"><div class="nav-item hide-in-mobile"><a href="/blog/" class="nav-link" aria-label="Blog Home"><span class="icon iconfont icon-home"></span>Blog Home<!----></a></div><div class="nav-item hide-in-mobile"><a href="/blog/category/" class="nav-link" aria-label="Category"><span class="icon iconfont icon-categoryselected"></span>Category<!----></a></div><div class="nav-item hide-in-mobile"><a href="/blog/tag/" class="nav-link" aria-label="Tags"><span class="icon iconfont icon-tag"></span>Tags<!----></a></div><div class="nav-item hide-in-mobile"><a href="/blog/timeline/" class="nav-link" aria-label="Timeline"><span class="icon iconfont icon-time"></span>Timeline<!----></a></div></nav><!----></div><div class="navbar-right"><!----><!----><div class="nav-item"><a class="repo-link" href="https://github.com/lileicc/blog" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" autocomplete="off" spellcheck="false" value><!----></form><!----><button class="toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span class="button-container"><span class="button-top"></span><span class="button-middle"></span><span class="button-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow left"></span></div><aside class="sidebar"><!--[--><!----><!--]--><ul class="sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main class="page" id="main-content"><!--[--><!----><nav class="breadcrumb disable"></nav><div class="page-title"><h1><!---->Exploiting Capacity for Multilingual Neural Machine Translation</h1><div class="page-info"><span class="author-info" aria-label="AuthorðŸ–Š" data-balloon-pos="down" localizeddate="November 19, 2021" isoriginal="false" pageview="false"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="author-item">Wenda Xu</span></span><span property="author" content="Wenda Xu"></span></span><!----><span class="date-info" aria-label="Writing DateðŸ“…" data-balloon-pos="down" isoriginal="false" pageview="false"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span>November 19, 2021</span><meta property="datePublished" content="2021-11-19T00:00:00.000Z"></span><span class="category-info" aria-label="CategoryðŸŒˆ" data-balloon-pos="down" localizeddate="November 19, 2021" isoriginal="false" pageview="false"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><ul class="categories-wrapper"><li class="category category4 clickable" role="navigation">MT</li><li class="category category1 clickable" role="navigation">DL4MT</li><meta property="articleSection" content="MT,DL4MT"></ul></span><span aria-label="TagðŸ·" data-balloon-pos="down" localizeddate="November 19, 2021" isoriginal="false" pageview="false"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><ul class="tags-wrapper"><li class="tag tag7 clickable" role="navigation">Multilingual MT</li><li class="tag tag1 clickable" role="navigation">Model Capacity</li><li class="tag tag0 clickable" role="navigation">Language-specific Sub-network</li></ul><meta property="keywords" content="Multilingual MT,Model Capacity,Language-specific Sub-network"></span><span class="reading-time-info" aria-label="Reading TimeâŒ›" data-balloon-pos="down" localizeddate="November 19, 2021" isoriginal="false" pageview="false"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 4 min</span><meta property="timeRequired" content="PT4M"></span></div><hr></div><!----><!----><div class="theme-hope-content"><p>Multiligual machine translation aims at learning a single tanslation model for multiple languages. However, high resource language often suffers from performance degradation. In this blog, we present a method LaSS proposed in a recent ACL paper on multilingual neural machine translation. The LaSS is an approach to jointly train a single unified multilingual MT model and learns language-specific subnetwork for each language pair. Authors conducted experiments on IWSLT and WMT datasets with various Transformer architectures. The experimental results demonstrates average 1.2 BLEU improvements on 36 language pairs. LaSS shows strong generalization capabilty and demonstrates strong performance in zero-shot translation. Specifically, LaSS achieves 8.3 BLEU on 30 language pairs.</p><!-- more --><h1 id="background-and-motivation" tabindex="-1"><a class="header-anchor" href="#background-and-motivation" aria-hidden="true">#</a> Background and motivation</h1><p>Recent research has forcused on the efficicacy of multilingual NMT, which supports translation from multiple source languages into multiple target languages with a single unified network. The parameter sharing of multilingual Machine Translation model encourages or enforce the parameter sharing between different languages. To demonstrate an extreme case - direct translation between a language pair never seen during the training.</p><p>The main challenge for the many-to-many multilingual machine translation is the insufficient model capacity. Since all the translation directions need to be learned in a single model, the model is forced to split out for different language pairs. In this case, rich resource language especially will suffer from the performance degradation. One may consider to enhance the model size to solve the issue. However, larger model size will accompany to the enlargement of dataset. To stay with the same model parameters, an alternatvie solution is to design language-aware components, for example, language-dependent hidden cells and language-aware layer normalization etc.</p><p>Therefore, to achieve a parameter-efficient network, without external trainable parameters for language-specific features, authors propose a Language Specific Subnetwork for multilingual NMT (LaSS). Each language pair in LaSS contains both language universal and language specific parameters. The network is trained to decide the sharing strategy. In particular, LaSS can model the language specific and language universal features for each language direction without interference.</p><p><img src="/blog/assets/lass.f39636c1.png" alt="lass"></p><h1 id="model-and-details" tabindex="-1"><a class="header-anchor" href="#model-and-details" aria-hidden="true">#</a> Model and details</h1><p>Overall idea for LaSS is to find sub-networks corresponding to each language pair and only updates the parameters of those sub-networks during the joint training (See Figure 1 for illustration). Authors adopt the multilingual Transformer as the backbone network. They train an initial multilingual MT model with the following loss:</p><p><img src="/blog/assets/eqn.6fb16690.png" alt="eqn"></p><p>&lt;x, y&gt; is a language pair from s to t. theta is the model parameter.</p><p>Start from multilingual base, authors try to find a sub-network which is specific to each language pair. Specific algorithm to find the language specific mask is following:</p><ol><li>Start with a multilingual MT model jointly trained on {D<sub>si-&gt;ti</sub>} from i=1 to i=N.</li><li>Fine-tunning theta on specific language pair s<sub>i</sub> to t<sub>i</sub> will amplify the magnitude of the important weights and diminish the unimportant weights.</li><li>Rank the weights in fine-tuned model and prune the lowest alpha percent. The mask M<sub>si-&gt;ti</sub> is obtained by setting the remaining indices of parameters to be 1.</li></ol><p>After getting masks for all the language pairs, authors create random batches of bilingual sentence pairs where each batch contains only samples from one pair. Specifically, a batch B<sub>si-&gt;ti</sub> is randomly drawn from the language-specific data D<sub>si-&gt;ti</sub>. During the backpropogation step, authors only update the parameters in theta belonging to the subnetworks, which are the M<sub>si-&gt;ti</sub> obtaiend from the step 3. The parameters are iteratively updated until convergence.</p><p>During the inference, model parameters are used along with the mask M<sub>si-&gt;ti</sub>. For every given input sentence in language s and a target language t, model only uses parameter theta with 1s indicated by mask M<sub>si-&gt;ti</sub> to produce the final inference result.</p><h1 id="experiment-results-and-analysis" tabindex="-1"><a class="header-anchor" href="#experiment-results-and-analysis" aria-hidden="true">#</a> Experiment results and analysis</h1><p>The experiments are conducted on IWSLT and WMT benchmarks. For IWSLT, we collect 8 English-centric language pairs from IWSLT2014. They apply byte pair encoding (BPE) to preprocess multilingual sentences, resulting in a vocabulary size of 30k for IWSLT and 64k for WMT.</p><p>LaSS consistently outperforms the multilingual baseline on all language pairs, confirming that using LaSS to alleviate parameter interference can help boost performance. Similarly, LaSS obtains consistent gains over multilingual baseline on WMT for both Transformer-base and Transformer-big. For Transformer-base, LaSS achieves an average improvement of 1.2 BLEU on 36 language pairs. For Transformer-large, LaSS obtains 0.6 BLEU improvement. Authors have three key observations: 1) As dataset scale increases, the improvement of BLEU and WR becomes larger, suggesting that the language pairs with large scale benefits more from LaSS. 2) Transformer-base gains more from the Transformer-big. This verfies the idea that more severe parameter interference for smaller models. 3) Authors also tested on random initialized masks, which is underperformed compared to the baselines. LaSS performance in IWLST and WMT compared to baseline and random initialized masks are included in Table 1 and Table 2, respectively.</p><p><img src="/blog/assets/iwslt.8ee6f2a6.png" alt="iwslt"><img src="/blog/assets/wmt.4583d45c.png" alt="wmt"></p><p>In this work, authors also demonstrate that LaSS can easily adapt to new unseen languages without dramatic drops for other existing languages. They distribute a new sub-network to each new language pair and train the sub-network with the specific language pair for fixed steps. In this way, the new language pair will only update the corresponding parameters and it can alleviate the interference and catastrophic forgetting to other language pairs. As demonstrated in the figure 2, LaSS hardly drops on other language pairs, while the multilingual baseline model dramatically drops by a large margin. LaSS also demonstrates its strong performance in zero-shot machine translation. Since LaSS strengthens its language specific parameters, apart from the language indicator, to the model to translate into the target language.</p><p><img src="/blog/assets/extenson.04161aa2.png" alt="extenson"></p><p>In the end, authors further analysized on the mask similarity and language family. They observed that for both En-&gt;X and X-&gt;En, the mask similarity is positively correlated to the language family similarity. Moreover, authors observed that on both the encoder and decoder side, the model tends to distribute more language specific components on the top and bottom layers rather than the middle ones. For fully-connected layer, the model tends to distribute more language specific capacity on the middle layers for the encoder, while distribute more language specific capacity in the decoder for the top layers. They also invertigate on how mask can improve zero-shot performance. They observed that replacing the encoder mask with other languages causes only littler performance drop, while replacing the decoder mask causes dramatic performance drop. Therefore, decoder mask is essential of performance improvement. Lastly, they found out for larger dataset, like WMT, a smaller pruning rate is better to keep the model capacity.</p><h1 id="_5-summary" tabindex="-1"><a class="header-anchor" href="#_5-summary" aria-hidden="true">#</a> 5. Summary</h1><p>In this work, authors proposed a framework to learn Language-Specific Sub-network (LaSS) for multilingual NMT. The consistent improvements are observed in both IWSLT and WMT datasets, which prove that LaSS is able to alleviate parameter interference and boost performance. They further demonstrated improved performance in new language pair, zero-shot machine translation. In the end, they included detailed analysis on mask-language family relations, language specific capacity, improved performance of mask over zero-shot MT and parameter choice of pruning parameter.</p><p>Code: <a href="https://github.com/NLP-Playground/LaSS" target="_blank" rel="noopener noreferrer">https://github.com/NLP-Playground/LaSS<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h1 id="reference" tabindex="-1"><a class="header-anchor" href="#reference" aria-hidden="true">#</a> Reference</h1><ul><li>Zehui Lin, Liwei Wu, Mingxuan Wang, Lei Li. Learning Language Specific Sub-network for Multilingual Machine Translation. ACL 2021. <a href="https://arxiv.org/abs/2105.09259" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2105.09259<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></div><!----><footer class="page-meta"><div class="meta-item edit-link"><a href="https://github.com/lileicc/blog/edit/main/dl4mt/2021/lass/README.md" rel="noopener noreferrer" target="_blank" aria-label="Edit this page" class="nav-link label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="edit icon"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div><div class="meta-item update-time"><span class="label">Last update: </span><span class="info">9/13/2022, 3:45:15 AM</span></div><div class="meta-item contributors"><span class="label">Contributors: </span><!--[--><!--[--><span class="contributor" title="email: lileicc@gmail.com">Lei Li</span><!--]--><!--]--></div></footer><!----><div class="giscus-wrapper input-top" style="display:block;"><div style="text-align:center">Loading...</div></div><!----><!--]--></main><!--]--><footer class="footer-wrapper"><div class="footer">Li Lab</div><div class="copyright">Copyright Â© 2023 Wenda Xu</div></footer><!--]--></div><!--]--><!----><!--]--></div>
    <script type="module" src="/blog/assets/app.a9a8508d.js" defer></script>
  </body>
</html>
